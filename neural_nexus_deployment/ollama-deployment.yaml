apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama-MODEL_NAME
  labels:
    app: ollama
    model: MODEL_NAME
    component: ai-model
spec:
  replicas: REPLICAS_COUNT
  selector:
    matchLabels:
      app: ollama
      model: MODEL_NAME
  template:
    metadata:
      labels:
        app: ollama
        model: MODEL_NAME
        component: ai-model
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
        runAsGroup: 1000
        fsGroup: 1000
        seccompProfile:
          type: RuntimeDefault
      initContainers:
      - name: model-downloader
        image: ollama/ollama:0.3.10
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop:
              - ALL
        command:
        - /bin/bash
        - -c
        - |
          echo "ü§ñ Downloading model: MODEL_FULL_NAME"
          
          # Model size estimates for user info
          case "MODEL_FULL_NAME" in
            *:2b*) echo "üìä Estimated download size: ~1.4GB" ;;
            *:3b*|*:3.8b*) echo "üìä Estimated download size: ~2.3GB" ;;
            *:7b*) echo "üìä Estimated download size: ~4.1GB" ;;
            *:8b*) echo "üìä Estimated download size: ~4.7GB" ;;
            *:13b*) echo "üìä Estimated download size: ~7.3GB" ;;
            *:34b*) echo "üìä Estimated download size: ~19GB" ;;
            *:70b*) echo "üìä Estimated download size: ~39GB" ;;
            *8x7b*) echo "üìä Estimated download size: ~26GB" ;;
            *) echo "üìä Estimated download size: ~4-8GB" ;;
          esac
          
          echo "‚è±Ô∏è This may take 5-30 minutes depending on your internet speed"
          echo "üöÄ Starting Ollama server..."
          
          ollama serve &
          OLLAMA_PID=$!
          
          # Wait for server to start with process check
          for i in {1..30}; do
            if pgrep -f "ollama serve" > /dev/null; then
              echo "‚úÖ Ollama server started"
              break
            fi
            echo "‚è≥ Waiting for Ollama server... ($i/30)"
            sleep 2
          done
          
          # Additional wait for API readiness
          sleep 5
          
          echo "üì• Starting download of MODEL_FULL_NAME..."
          echo "üí° Tip: You can monitor progress with 'make logs-ollama MODEL=MODEL_NAME FOLLOW=true'"
          
          # Create a background job to show periodic progress updates
          (
            sleep 10
            while kill -0 $OLLAMA_PID 2>/dev/null; do
              if [ -d "/root/.ollama/models" ]; then
                CURRENT_SIZE=$(du -sh /root/.ollama/models 2>/dev/null | cut -f1 || echo "0B")
                echo "üìà Downloaded so far: $CURRENT_SIZE"
              fi
              sleep 30
            done
          ) &
          PROGRESS_PID=$!
          
          if ollama pull MODEL_FULL_NAME; then
            echo "‚úÖ Model downloaded successfully!"
            FINAL_SIZE=$(du -sh /root/.ollama/models 2>/dev/null | cut -f1 || echo "Unknown")
            echo "üíæ Total model storage: $FINAL_SIZE"
          else
            echo "‚ùå Model download failed"
            exit 1
          fi
          
          # Cleanup background processes
          kill $PROGRESS_PID 2>/dev/null || true
          kill $OLLAMA_PID
          wait $OLLAMA_PID 2>/dev/null || true
          
          echo "üîç Verifying model files..."
          ls -la /root/.ollama/models/
        env:
        - name: OLLAMA_HOST
          value: "0.0.0.0"
        - name: OLLAMA_MODELS
          value: "/root/.ollama/models"
        volumeMounts:
        - name: ollama-models
          mountPath: /root/.ollama/models
        - name: ollama-cache
          mountPath: /tmp/ollama
        resources:
          requests:
            cpu: "1"
            memory: "2Gi"
          limits:
            cpu: "2"
            memory: "4Gi"
      containers:
      - name: ollama
        image: ollama/ollama:0.3.10
        ports:
        - containerPort: 11434
          name: http
          protocol: TCP
        securityContext:
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: false
          runAsNonRoot: true
          runAsUser: 1000
          runAsGroup: 1000
          capabilities:
            drop:
              - ALL
        env:
        - name: OLLAMA_HOST
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_HOST
        - name: OLLAMA_PORT
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_PORT
        - name: OLLAMA_MODELS
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_MODELS
        - name: OLLAMA_KEEP_ALIVE
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_KEEP_ALIVE
        - name: OLLAMA_MAX_LOADED_MODELS
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_MAX_LOADED_MODELS
        - name: OLLAMA_NUM_PARALLEL
          valueFrom:
            configMapKeyRef:
              name: ollama-config
              key: OLLAMA_NUM_PARALLEL
        # GPU_PLACEHOLDER - Will be replaced with GPU resources if GPU=true
        volumeMounts:
        - name: ollama-models
          mountPath: /root/.ollama/models
        - name: ollama-cache
          mountPath: /tmp/ollama
        resources:
          requests:
            cpu: CPU_REQUEST
            memory: MEMORY_REQUEST
          limits:
            cpu: CPU_LIMIT
            memory: MEMORY_LIMIT
        readinessProbe:
          httpGet:
            path: /api/version
            port: 11434
          initialDelaySeconds: 30
          periodSeconds: 10
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 3
        livenessProbe:
          httpGet:
            path: /api/version
            port: 11434
          initialDelaySeconds: 60
          periodSeconds: 30
          timeoutSeconds: 10
          failureThreshold: 3
        startupProbe:
          httpGet:
            path: /api/version
            port: 11434
          initialDelaySeconds: 10
          periodSeconds: 5
          timeoutSeconds: 5
          successThreshold: 1
          failureThreshold: 20
      volumes:
      - name: ollama-models
        persistentVolumeClaim:
          claimName: ollama-models-pvc
      - name: ollama-cache
        persistentVolumeClaim:
          claimName: ollama-cache-pvc
      restartPolicy: Always